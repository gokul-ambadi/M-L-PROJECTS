{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5c52238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"C:/Users/ambad/OneDrive/Desktop/nlp_dataset (3).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d03db4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i seriously hate one subject to death but now ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im so full of life i feel appalled</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here to write i start to dig out my feel...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive been really angry with r and i feel like a...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel suspicious if there is no one outside l...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>i begun to feel distressed for you</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>i left feeling annoyed and angry thinking that...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>i were to ever get married i d have everything...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5935</th>\n",
       "      <td>i feel reluctant in applying there because i w...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5936</th>\n",
       "      <td>i just wanted to apologize to you because i fe...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5937 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment Emotion\n",
       "0     i seriously hate one subject to death but now ...    fear\n",
       "1                    im so full of life i feel appalled   anger\n",
       "2     i sit here to write i start to dig out my feel...    fear\n",
       "3     ive been really angry with r and i feel like a...     joy\n",
       "4     i feel suspicious if there is no one outside l...    fear\n",
       "...                                                 ...     ...\n",
       "5932                 i begun to feel distressed for you    fear\n",
       "5933  i left feeling annoyed and angry thinking that...   anger\n",
       "5934  i were to ever get married i d have everything...     joy\n",
       "5935  i feel reluctant in applying there because i w...    fear\n",
       "5936  i just wanted to apologize to you because i fe...   anger\n",
       "\n",
       "[5937 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "154b82cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data['Comment']\n",
    "y=data['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48d93542",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ambad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ambad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1741b2",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "683bb732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       i seriously hate one subject to death but now ...\n",
       "1                      im so full of life i feel appalled\n",
       "2       i sit here to write i start to dig out my feel...\n",
       "3       ive been really angry with r and i feel like a...\n",
       "4       i feel suspicious if there is no one outside l...\n",
       "                              ...                        \n",
       "5932                   i begun to feel distressed for you\n",
       "5933    i left feeling annoyed and angry thinking that...\n",
       "5934    i were to ever get married i d have everything...\n",
       "5935    i feel reluctant in applying there because i w...\n",
       "5936    i just wanted to apologize to you because i fe...\n",
       "Name: Comment, Length: 5937, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20b3d27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [i, seriously, hate, one, subject, to, death, ...\n",
       "1             [im, so, full, of, life, i, feel, appalled]\n",
       "2       [i, sit, here, to, write, i, start, to, dig, o...\n",
       "3       [ive, been, really, angry, with, r, and, i, fe...\n",
       "4       [i, feel, suspicious, if, there, is, no, one, ...\n",
       "                              ...                        \n",
       "5932           [i, begun, to, feel, distressed, for, you]\n",
       "5933    [i, left, feeling, annoyed, and, angry, thinki...\n",
       "5934    [i, were, to, ever, get, married, i, d, have, ...\n",
       "5935    [i, feel, reluctant, in, applying, there, beca...\n",
       "5936    [i, just, wanted, to, apologize, to, you, beca...\n",
       "Name: Comment, Length: 5937, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "x_tokenized=x.apply(word_tokenize)\n",
    "x_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d96209",
   "metadata": {},
   "source": [
    "# Lowercase Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "977f133f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [i, seriously, hate, one, subject, to, death, ...\n",
       "1             [im, so, full, of, life, i, feel, appalled]\n",
       "2       [i, sit, here, to, write, i, start, to, dig, o...\n",
       "3       [ive, been, really, angry, with, r, and, i, fe...\n",
       "4       [i, feel, suspicious, if, there, is, no, one, ...\n",
       "                              ...                        \n",
       "5932           [i, begun, to, feel, distressed, for, you]\n",
       "5933    [i, left, feeling, annoyed, and, angry, thinki...\n",
       "5934    [i, were, to, ever, get, married, i, d, have, ...\n",
       "5935    [i, feel, reluctant, in, applying, there, beca...\n",
       "5936    [i, just, wanted, to, apologize, to, you, beca...\n",
       "Name: Comment, Length: 5937, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_lowercase=x_tokenized.apply(lambda tokens:[token.lower() for token in tokens])\n",
    "x_lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01967f0e",
   "metadata": {},
   "source": [
    "# stopwords removel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f77b848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ambad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4547e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words=set(stopwords.words('english'))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "360da01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [seriously, hate, one, subject, death, feel, r...\n",
       "1                        [im, full, life, feel, appalled]\n",
       "2       [sit, write, start, dig, feelings, think, afra...\n",
       "3       [ive, really, angry, r, feel, like, idiot, tru...\n",
       "4       [feel, suspicious, one, outside, like, rapture...\n",
       "                              ...                        \n",
       "5932                            [begun, feel, distressed]\n",
       "5933    [left, feeling, annoyed, angry, thinking, cent...\n",
       "5934    [ever, get, married, everything, ready, offer,...\n",
       "5935    [feel, reluctant, applying, want, able, find, ...\n",
       "5936    [wanted, apologize, feel, like, heartless, bitch]\n",
       "Name: Comment, Length: 5937, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stopwords=x_lowercase.apply(lambda i:[word for word in i if word not in stop_words])\n",
    "x_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ff9b3d",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "106c916f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ambad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ambad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea5ed4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [seriously, hate, one, subject, death, feel, r...\n",
       "1                        [im, full, life, feel, appalled]\n",
       "2       [sit, write, start, dig, feeling, think, afrai...\n",
       "3       [ive, really, angry, r, feel, like, idiot, tru...\n",
       "4       [feel, suspicious, one, outside, like, rapture...\n",
       "                              ...                        \n",
       "5932                            [begun, feel, distressed]\n",
       "5933    [left, feeling, annoyed, angry, thinking, cent...\n",
       "5934    [ever, get, married, everything, ready, offer,...\n",
       "5935    [feel, reluctant, applying, want, able, find, ...\n",
       "5936    [wanted, apologize, feel, like, heartless, bitch]\n",
       "Name: Comment, Length: 5937, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizar=WordNetLemmatizer()\n",
    "lemmatized_tokens=x_stopwords.apply(lambda i:[lemmatizar.lemmatize(word) for word in i])\n",
    "lemmatized_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665d9722",
   "metadata": {},
   "source": [
    "# Avoid Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac7cf5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3650f087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [seriously, hate, one, subject, death, feel, r...\n",
       "1                        [im, full, life, feel, appalled]\n",
       "2       [sit, write, start, dig, feeling, think, afrai...\n",
       "3       [ive, really, angry, r, feel, like, idiot, tru...\n",
       "4       [feel, suspicious, one, outside, like, rapture...\n",
       "                              ...                        \n",
       "5932                            [begun, feel, distressed]\n",
       "5933    [left, feeling, annoyed, angry, thinking, cent...\n",
       "5934    [ever, get, married, everything, ready, offer,...\n",
       "5935    [feel, reluctant, applying, want, able, find, ...\n",
       "5936    [wanted, apologize, feel, like, heartless, bitch]\n",
       "Name: Comment, Length: 5937, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_punct=lemmatized_tokens.apply(lambda i:[word for word in i if word not in string.punctuation])\n",
    "tokens_punct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961e8133",
   "metadata": {},
   "source": [
    "# feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1eeb5d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer=CountVectorizer()\n",
    "x_vectorized=vectorizer.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a44cc222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2342692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x_vectorized,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36b6834",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ab91553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91222dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model=MultinomialNB()\n",
    "nb_model.fit(x_train,y_train)\n",
    "y_pred_nb=nb_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "038229e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy: 0.8939393939393939\n",
      "Classification report for Naive Bayes:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.88      0.92      0.90       392\n",
      "        fear       0.88      0.92      0.90       416\n",
      "         joy       0.92      0.84      0.88       380\n",
      "\n",
      "    accuracy                           0.89      1188\n",
      "   macro avg       0.90      0.89      0.89      1188\n",
      "weighted avg       0.89      0.89      0.89      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes accuracy:\",accuracy_score(y_test,y_pred_nb))\n",
    "print(\"Classification report for Naive Bayes:\\n\",classification_report(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1004ae23",
   "metadata": {},
   "source": [
    "# support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43984397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model=SVC(kernel=\"linear\")\n",
    "svm_model.fit(x_train,y_train)\n",
    "y_pred_svm=svm_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5aeb495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm accuracy: 0.9486531986531986\n",
      "Classification report for svm:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.92      0.96      0.94       392\n",
      "        fear       0.97      0.92      0.95       416\n",
      "         joy       0.96      0.96      0.96       380\n",
      "\n",
      "    accuracy                           0.95      1188\n",
      "   macro avg       0.95      0.95      0.95      1188\n",
      "weighted avg       0.95      0.95      0.95      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"svm accuracy:\",accuracy_score(y_test,y_pred_svm))\n",
    "print('Classification report for svm:\\n',classification_report(y_test,y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4804324e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix for Naive Bayes:\n",
      " [[359  21  12]\n",
      " [ 18 382  16]\n",
      " [ 30  29 321]]\n",
      "confusion matrix for svm:\n",
      " [[377   7   8]\n",
      " [ 24 384   8]\n",
      " [  9   5 366]]\n",
      "Naive Bayes accuracy: 0.8939393939393939\n",
      "svm accuracy: 0.9486531986531986\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix for Naive Bayes:\\n', confusion_matrix(y_test,y_pred_nb))\n",
    "\n",
    "print('confusion matrix for svm:\\n', confusion_matrix(y_test,y_pred_svm))\n",
    "\n",
    "print('Naive Bayes accuracy:', accuracy_score(y_test,y_pred_nb))\n",
    "\n",
    "print('svm accuracy:', accuracy_score(y_test,y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24acb44d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
